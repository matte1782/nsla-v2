# **NSLA-v2 ‚Äî Neuro-Symbolic Legal Assistant (Research Prototype)**
### **Hybrid Technical + Academic Project Overview**
**Author:** Matteo Panzeri  
**Status:** Research Prototype (Paused)  
**Year:** 2025  

---

# üöÄ **1. Project Summary**
NSLA-v2 is a **neuro-symbolic research prototype** exploring whether *pure logical entailment using Z3* can be used as the core reasoning mechanism for legal tasks such as:
- contract interpretation,
- clause consistency,
- obligation entailment,
- contradiction detection.

The prototype combines:
- **structured extraction**,
- a custom **legal DSL**,
- a multi-stage **neuro-symbolic pipeline**,
- **Z3 SMT-based reasoning**,
- and iterative feedback loops.

### ‚ùó Important
This project represents a **negative research result**: while the engineering is correct, the theoretical foundations make Z3-based legal interpretation structurally unsuitable. 

Despite this limitation, the project produced:
- reusable code modules,
- a clean neuro-symbolic pipeline,
- DSL design patterns,
- a large test suite,
- and several new research directions.

It is published as a **case study in failure-driven research**, demonstrating critical thinking and scientific reasoning.

---

# üß† **2. Motivation**
Legal reasoning appears rule-like and logic-driven, making it a tempting domain for symbolic and neuro-symbolic systems. The goal was to test whether:

```
Text ‚Üí Structured Extraction ‚Üí DSL ‚Üí Logic ‚Üí Z3 ‚Üí Legal Entailment
```

‚Ä¶could work reliably.

What we found is equally valuable:
> **The mismatch between law (non-monotonic, contextual, interpretative) and SMT solvers (monotonic, fully specified) makes pure logical entailment insufficient.**

This insight allowed us to pivot toward more promising research directions.

---

# üèóÔ∏è **3. Architecture / System Design**

NSLA-v2 implements a **multi-stage neuro-symbolic pipeline** that combines LLM-based structured extraction with formal reasoning via Z3. The architecture is modular, testable, and designed for failure analysis‚Äîcritical for understanding the limits of SMT-based legal reasoning.

### **Pipeline Flow**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input: Legal Question (Natural Language)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2.1: Canonicalization (LLM)                                 ‚îÇ
‚îÇ  ‚Üí Extracts domain, concepts, unmapped terms                       ‚îÇ
‚îÇ  ‚Üí Module: canonicalizer_runtime.py                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2.2: Structured Extraction (LLM ‚Üí DSL)                      ‚îÇ
‚îÇ  ‚Üí Converts NL to LogicProgram (predicates, axioms, rules, query)  ‚îÇ
‚îÇ  ‚Üí Hydrates ontology from resources/ontology/legal_it_v1.yaml      ‚îÇ
‚îÇ  ‚Üí Module: structured_extractor.py                                 ‚îÇ
‚îÇ  ‚Üí DSL spec: logic_dsl.py (version 2.1)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2.3: Refinement (LLM feedback loop)                         ‚îÇ
‚îÇ  ‚Üí Receives Z3 feedback from v1 program                            ‚îÇ
‚îÇ  ‚Üí Generates refined LogicProgram v2 + final_answer                ‚îÇ
‚îÇ  ‚Üí Module: refinement_runtime.py                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2.4: Guardrail Checker                                      ‚îÇ
‚îÇ  ‚Üí Validates DSL version, predicate arities, sort compatibility    ‚îÇ
‚îÇ  ‚Üí Prevents malformed programs from reaching translator            ‚îÇ
‚îÇ  ‚Üí Module: guardrail_checker.py                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Translator + Z3 Solver                                            ‚îÇ
‚îÇ  ‚Üí Encodes DSL into Z3 constraints (sorts ‚Üí DatatypeSort)          ‚îÇ
‚îÇ  ‚Üí Builds solver with axioms, rules, query                         ‚îÇ
‚îÇ  ‚Üí Module: translator.py (DSL21Parser)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Z3 Solver Result ‚Üí Logic Feedback                                 ‚îÇ
‚îÇ  ‚Üí Status: consistent_entails | consistent_no_entailment |         ‚îÇ
‚îÇ             inconsistent                                            ‚îÇ
‚îÇ  ‚Üí Missing links, conflicting axioms, human summary                ‚îÇ
‚îÇ  ‚Üí Module: logic_feedback.py                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Phase 2.5: Explanation Synthesis                                  ‚îÇ
‚îÇ  ‚Üí Generates human-readable explanation from feedback              ‚îÇ
‚îÇ  ‚Üí Module: explanation_synthesizer.py                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (Optional) Phase 3: Iterative Refinement                          ‚îÇ
‚îÇ  ‚Üí Bounded loop: LLM ‚Üî Z3 feedback (max_iters configurable)       ‚îÇ
‚îÇ  ‚Üí Selects best iteration by heuristic (status priority)           ‚îÇ
‚îÇ  ‚Üí Module: iteration_manager.py                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (Optional) Phase 4: Judge-LLM Evaluation                          ‚îÇ
‚îÇ  ‚Üí Compares baseline vs. NSLA-v2 answer against reference          ‚îÇ
‚îÇ  ‚Üí Module: judge_runtime.py                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
                  Final Output
```

### **Module-to-Stage Mapping**

| **Pipeline Stage**          | **Module/File**                      | **Key Responsibilities**                                                                 |
|-----------------------------|--------------------------------------|------------------------------------------------------------------------------------------|
| **Orchestration**           | `pipeline_v2.py`                     | Coordinates all phases, manages LLM status, fact synthesis, program sanitization        |
| **DSL Specification**       | `logic_dsl.py`                       | Defines canonical sorts (Debitore, Contratto, etc.), predicates, DSL version (2.1)      |
| **Ontology Utilities**      | `ontology_utils.py`                  | Resolves predicate/sort aliases (e.g., "Soggetto obbligato" ‚Üí "Debitore")               |
| **Canonicalization**        | `canonicalizer_runtime.py`           | Phase 2.1: Domain extraction, concept identification                                     |
| **Structured Extraction**   | `structured_extractor.py`            | Phase 2.2: NL ‚Üí LogicProgram, hydrates sorts/predicates from ontology                    |
| **Refinement**              | `refinement_runtime.py`              | Phase 2.3: Iterative LLM refinement using Z3 feedback                                    |
| **Guardrail**               | `guardrail_checker.py`               | Phase 2.4: Static validation (DSL version, arity, sorts)                                 |
| **Z3 Translation**          | `translator.py`                      | Encodes DSL into Z3 (DSL21Parser), builds solver, handles fact synthesis                |
| **Logic Feedback**          | `logic_feedback.py`                  | Interprets Z3 results (sat/unsat/unknown) into actionable feedback                      |
| **Explanation**             | `explanation_synthesizer.py`         | Phase 2.5: Generates human-readable summaries                                            |
| **Iteration Manager**       | `iteration_manager.py`               | Phase 3: Bounded refinement loop with state tracking                                     |
| **Judge Metric**            | `judge_runtime.py`                   | Phase 4: LLM-based evaluation of baseline vs. NSLA-v2 answers                           |
| **Canonical Rules**         | `canonical_rule_utils.py`            | Ensures query rules follow DSL conventions                                               |
| **Data Models**             | `models.py`, `models_v2.py`          | Pydantic schemas: LogicProgram, LLMOutput, IterationState, GuardrailResult, etc.        |

### **Testing & Validation**

The codebase includes comprehensive tests that validate each stage:

- **Unit Tests**: `test_translator_autodeclare.py`, `test_guardrail_checker.py`, `test_structured_extractor_ontology.py`, `test_logic_feedback.py`
- **Integration Tests**: `test_phase2_e2e.py`, `test_phase3_e2e.py`, `test_phase2_runtimes.py`
- **Golden Cases**: `test_nsla_v2_golden_cases.py` ‚Äî validates legal reasoning patterns (contractual liability, tort law, usucapion)
- **Component Tests**: `test_iteration_manager.py`, `test_explanation_synthesizer.py`, `test_judge_runtime.py`
- **Smoke Tests**: `test_benchmark_smoke.py` ‚Äî validates benchmark infrastructure

Run tests:
```bash
pytest -v
```

### **Research Value & Insights**

This architecture is designed for **failure-driven research**:

1. **Neuro-Symbolic Integration**: Demonstrates how LLMs can interface with formal reasoning (Z3) through a typed DSL, showcasing both strengths (structured extraction) and weaknesses (semantic loss).

2. **Formal Verification Layer**: The guardrail + translator pipeline ensures that only well-formed logical programs reach Z3, making failures attributable to reasoning (not syntax).

3. **Iterative Feedback Loop**: Phase 3 implements a bounded refinement mechanism where Z3 feedback (missing links, conflicts) guides LLM re-generation‚Äîa pattern reusable in other symbolic AI domains.

4. **Documented Limitations**: The architecture exposes **why Z3 fails for legal reasoning**:
   - **Non-monotonicity**: Legal conclusions change with new context; Z3 assumes monotonic logic.
   - **Semantic loss**: NL ‚Üí DSL translation strips nuance (intent, context, interpretation).
   - **Over-specification**: Law tolerates ambiguity; Z3 requires complete, consistent axioms.
   - **Entailment mismatch**: SAT/UNSAT ‚â† legal validity (e.g., contract interpretation involves policy, not pure logic).

5. **Reusable Components**: Despite the theoretical mismatch, the modules (structured extraction, ontology mapping, iterative refinement, guardrails) are **directly applicable** to domains where formal reasoning is viable (e.g., compliance checking, configuration synthesis, protocol verification).

6. **Benchmarking Infrastructure**: The test suite provides reproducible failure cases, enabling future research to measure progress on neuro-symbolic legal reasoning or pivot to better-suited formalisms (e.g., non-monotonic logics, probabilistic reasoning).

### **Why This Design Matters**

For **research recruiters** evaluating this project:
- This is not a failed product‚Äîit's a **successful scientific experiment** that disproves a hypothesis.
- The architecture demonstrates **systems thinking**: modularity, testability, instrumentation (LLM status tracking, guardrails, feedback loops).
- The codebase is **publication-ready**: clear separation of concerns, comprehensive tests, documented limitations.
- The negative result **guides future research**: highlights where symbolic AI needs augmentation (e.g., probabilistic layers, defeasible reasoning, hybrid retrieval).

This project exemplifies the kind of **rigorous, failure-tolerant research** essential for advancing AI in complex, interpretive domains like law.

---

# üì¶ **4. Repository Structure**
```
nsla-v2/
‚îú‚îÄ‚îÄ app/                           # Main application code (core logic)
‚îÇ   ‚îú‚îÄ‚îÄ templates/                 # Templates for prompts/UI
‚îÇ   ‚îú‚îÄ‚îÄ logic_dsl.py              # DSL specification (v2.1)
‚îÇ   ‚îú‚îÄ‚îÄ translator.py             # Z3 translator (DSL ‚Üí SMT)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_v2.py            # Main pipeline orchestration
‚îÇ   ‚îú‚îÄ‚îÄ guardrail_checker.py      # DSL validation & guardrails
‚îÇ   ‚îú‚îÄ‚îÄ structured_extractor.py   # Phase 2.2: NL ‚Üí DSL
‚îÇ   ‚îú‚îÄ‚îÄ canonicalizer_runtime.py  # Phase 2.1: Domain extraction
‚îÇ   ‚îú‚îÄ‚îÄ refinement_runtime.py     # Phase 2.3: Iterative refinement
‚îÇ   ‚îú‚îÄ‚îÄ explanation_synthesizer.py # Phase 2.5: Human-readable output
‚îÇ   ‚îú‚îÄ‚îÄ iteration_manager.py      # Phase 3: Bounded refinement loop
‚îÇ   ‚îú‚îÄ‚îÄ judge_runtime.py          # Phase 4: LLM-based evaluation
‚îÇ   ‚îú‚îÄ‚îÄ logic_feedback.py         # Z3 result interpretation
‚îÇ   ‚îú‚îÄ‚îÄ ontology_utils.py         # Ontology mapping utilities
‚îÇ   ‚îú‚îÄ‚îÄ models.py / models_v2.py  # Pydantic data models
‚îÇ   ‚îî‚îÄ‚îÄ ...                       # Other modules
‚îú‚îÄ‚îÄ tests/                         # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_translator_autodeclare.py    # Unit: Z3 translator
‚îÇ   ‚îú‚îÄ‚îÄ test_guardrail_checker.py         # Unit: Guardrail validation
‚îÇ   ‚îú‚îÄ‚îÄ test_structured_extractor_ontology.py  # Unit: DSL extraction
‚îÇ   ‚îú‚îÄ‚îÄ test_logic_feedback.py            # Unit: Z3 feedback
‚îÇ   ‚îú‚îÄ‚îÄ test_phase2_e2e.py                # Integration: Phase 2
‚îÇ   ‚îú‚îÄ‚îÄ test_phase3_e2e.py                # Integration: Phase 3
‚îÇ   ‚îú‚îÄ‚îÄ test_nsla_v2_golden_cases.py      # Golden test cases
‚îÇ   ‚îî‚îÄ‚îÄ ...                               # Other tests
‚îú‚îÄ‚îÄ docs/                          # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ nsla_v2/                   # Project-specific docs
‚îÇ       ‚îú‚îÄ‚îÄ json/                  # JSON schemas/examples
‚îÇ       ‚îú‚îÄ‚îÄ reports/               # Analysis reports
‚îÇ       ‚îú‚îÄ‚îÄ dsl_nsla_v_2_1.md     # DSL guide
‚îÇ       ‚îú‚îÄ‚îÄ logic_dsl_v2.md       # DSL specification
‚îÇ       ‚îú‚îÄ‚îÄ nsla_v_2_phase_3_pipeline.md  # Phase 3 design
‚îÇ       ‚îî‚îÄ‚îÄ ...                    # Other documentation
‚îú‚îÄ‚îÄ data/                          # Test cases & benchmark results
‚îÇ   ‚îú‚îÄ‚îÄ cases_dev.json            # Development test cases
‚îÇ   ‚îî‚îÄ‚îÄ results_*.csv             # Benchmark outputs
‚îú‚îÄ‚îÄ resources/                     # Static resources
‚îÇ   ‚îú‚îÄ‚îÄ ontology/                 # Legal domain ontology
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ legal_it_v1.yaml     # Italian legal ontology
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                  # LLM prompt templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ phase3/              # Phase 3 prompts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ judge/               # Judge LLM prompts
‚îÇ   ‚îî‚îÄ‚îÄ specs/                    # Formal specifications
‚îú‚îÄ‚îÄ scripts/                       # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ inspect_subset_guardrail.py
‚îÇ   ‚îî‚îÄ‚îÄ manual_sanity.py
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ README.md                      # This file
‚îú‚îÄ‚îÄ nsla_v2_paper_en.md           # Research paper (English)
‚îî‚îÄ‚îÄ nsla_v2_paper_it.md           # Research paper (Italian)
```

---

# üî¨ **5. Key Findings**
### ‚úî What works well
- DSL design is clean and expressive.
- Guardrail system handles malformed DSL robustly.
- Z3 encodings are deterministic and well-formed.
- Unit and integration tests pass consistently on structured cases.
- Pipeline is modular and maintainable.

### ‚úò What fundamentally fails
1. **Semantic loss**: Natural language ‚Üí DSL strips essential meaning.
2. **Non-monotonicity**: Legal reasoning changes with added context; SMT cannot.
3. **Over-specification**: Law tolerates ambiguity; Z3 requires completeness.
4. **Interpretive reasoning**: Legal judgement is contextual, not purely logical.
5. **Entailment mismatch**: Solver SAT/UNSAT ‚â† legal validity.

### üéì Scientific insight
> Legal reasoning cannot be reliably reduced to monotonic logical entailment.

This negative result is useful to guide future research.

---

# üß™ **6. Experiments & Testing**
NSLA-v2 includes:
- DSL validation tests
- Z3 translator tests
- end-to-end pipeline tests
- adversarial malformed-DSL scenarios
- benchmark micro-cases (contracts, obligations, contradictions)

Run tests:
```bash
pytest -v
```

---

# ‚ö†Ô∏è **7. Project Status**
### **Status: Paused Research Prototype**
The project is kept public as:
- a case study of neuro-symbolic system design,
- a record of limitations of SMT-based legal reasoning,
- a foundation for future experiments.

See: `docs/PAPER_DRAFT_EN.md` for full explanation.

---

# üî≠ **8. Future Research Directions**
This project directly inspired several more promising lines of work:

### **1. BinaryLLM Protocol**
Binary latent representations for ultra-low-energy inference.

### **2. Neuro-Symbolic Concept Generator**
Generate abstract mathematical propositions ‚Üí verify with Z3.

### **3. Fractal Reasoning Engine**
Multi-layer reasoning engine with internal self-verification loops.

All of these exploit the strengths of symbolic solvers without forcing them into domains they cannot model.

---

# ‚ñ∂Ô∏è **9. How to Use / Run**
Install dependencies:
```bash
pip install -r requirements.txt
```

Execute pipeline (example):
```bash
python src/pipeline_iterative.py
```

Run benchmarks:
```bash
pytest -v tests/
```

---

# üë§ **10. Author**
This project was developed by **Matteo Panzeri**, with the assistance of advanced LLM-based research tools used responsibly to accelerate architectural exploration, debugging, and documentation.

---

# üìÑ **11. License**
MIT License (recommended for research prototypes).