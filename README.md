# **NSLA-v2 â€” Neuro-Symbolic Legal Assistant (Research Prototype)**
### **Hybrid Technical + Academic Project Overview**
**Author:** Matteo Panzeri  
**Status:** Research Prototype (Paused)  
**Year:** 2025  

---
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Status: Research Prototype](https://img.shields.io/badge/status-research%20prototype-orange.svg)]
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)]
---
# ğŸš€ **1. Project Summary**
NSLA-v2 is a **neuro-symbolic research prototype** exploring whether *pure logical entailment using Z3* can be used as the core reasoning mechanism for legal tasks such as:
- contract interpretation,
- clause consistency,
- obligation entailment,
- contradiction detection.

The prototype combines:
- **structured extraction**,
- a custom **legal DSL**,
- a multi-stage **neuro-symbolic pipeline**,
- **Z3 SMT-based reasoning**,
- and iterative feedback loops.

### â— Important
This project represents a **negative research result**: while the engineering is correct, the theoretical foundations make Z3-based legal interpretation structurally unsuitable. 

Despite this limitation, the project produced:
- reusable code modules,
- a clean neuro-symbolic pipeline,
- DSL design patterns,
- a large test suite,
- and several new research directions.

It is published as a **case study in failure-driven research**, demonstrating critical thinking and scientific reasoning.

---

# ğŸ§  **2. Motivation**
Legal reasoning appears rule-like and logic-driven, making it a tempting domain for symbolic and neuro-symbolic systems. The goal was to test whether:

```
Text â†’ Structured Extraction â†’ DSL â†’ Logic â†’ Z3 â†’ Legal Entailment
```

â€¦could work reliably.

What we found is equally valuable:
> **The mismatch between law (non-monotonic, contextual, interpretative) and SMT solvers (monotonic, fully specified) makes pure logical entailment insufficient.**

This insight allowed us to pivot toward more promising research directions.

---

# ğŸ—ï¸ **3. Architecture / System Design**

NSLA-v2 implements a **multi-stage neuro-symbolic pipeline** that combines LLM-based structured extraction with formal reasoning via Z3. The architecture is modular, testable, and designed for failure analysisâ€”critical for understanding the limits of SMT-based legal reasoning.

### **Pipeline Flow**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: Legal Question (Natural Language)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2.1: Canonicalization (LLM)                                 â”‚
â”‚  â†’ Extracts domain, concepts, unmapped terms                       â”‚
â”‚  â†’ Module: canonicalizer_runtime.py                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2.2: Structured Extraction (LLM â†’ DSL)                      â”‚
â”‚  â†’ Converts NL to LogicProgram (predicates, axioms, rules, query)  â”‚
â”‚  â†’ Hydrates ontology from resources/ontology/legal_it_v1.yaml      â”‚
â”‚  â†’ Module: structured_extractor.py                                 â”‚
â”‚  â†’ DSL spec: logic_dsl.py (version 2.1)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2.3: Refinement (LLM feedback loop)                         â”‚
â”‚  â†’ Receives Z3 feedback from v1 program                            â”‚
â”‚  â†’ Generates refined LogicProgram v2 + final_answer                â”‚
â”‚  â†’ Module: refinement_runtime.py                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2.4: Guardrail Checker                                      â”‚
â”‚  â†’ Validates DSL version, predicate arities, sort compatibility    â”‚
â”‚  â†’ Prevents malformed programs from reaching translator            â”‚
â”‚  â†’ Module: guardrail_checker.py                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Translator + Z3 Solver                                            â”‚
â”‚  â†’ Encodes DSL into Z3 constraints (sorts â†’ DatatypeSort)          â”‚
â”‚  â†’ Builds solver with axioms, rules, query                         â”‚
â”‚  â†’ Module: translator.py (DSL21Parser)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Z3 Solver Result â†’ Logic Feedback                                 â”‚
â”‚  â†’ Status: consistent_entails | consistent_no_entailment |         â”‚
â”‚             inconsistent                                            â”‚
â”‚  â†’ Missing links, conflicting axioms, human summary                â”‚
â”‚  â†’ Module: logic_feedback.py                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2.5: Explanation Synthesis                                  â”‚
â”‚  â†’ Generates human-readable explanation from feedback              â”‚
â”‚  â†’ Module: explanation_synthesizer.py                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  (Optional) Phase 3: Iterative Refinement                          â”‚
â”‚  â†’ Bounded loop: LLM â†” Z3 feedback (max_iters configurable)       â”‚
â”‚  â†’ Selects best iteration by heuristic (status priority)           â”‚
â”‚  â†’ Module: iteration_manager.py                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  (Optional) Phase 4: Judge-LLM Evaluation                          â”‚
â”‚  â†’ Compares baseline vs. NSLA-v2 answer against reference          â”‚
â”‚  â†’ Module: judge_runtime.py                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
                  Final Output
```

### **Module-to-Stage Mapping**

| **Pipeline Stage**          | **Module/File**                      | **Key Responsibilities**                                                                 |
|-----------------------------|--------------------------------------|------------------------------------------------------------------------------------------|
| **Orchestration**           | `pipeline_v2.py`                     | Coordinates all phases, manages LLM status, fact synthesis, program sanitization        |
| **DSL Specification**       | `logic_dsl.py`                       | Defines canonical sorts (Debitore, Contratto, etc.), predicates, DSL version (2.1)      |
| **Ontology Utilities**      | `ontology_utils.py`                  | Resolves predicate/sort aliases (e.g., "Soggetto obbligato" â†’ "Debitore")               |
| **Canonicalization**        | `canonicalizer_runtime.py`           | Phase 2.1: Domain extraction, concept identification                                     |
| **Structured Extraction**   | `structured_extractor.py`            | Phase 2.2: NL â†’ LogicProgram, hydrates sorts/predicates from ontology                    |
| **Refinement**              | `refinement_runtime.py`              | Phase 2.3: Iterative LLM refinement using Z3 feedback                                    |
| **Guardrail**               | `guardrail_checker.py`               | Phase 2.4: Static validation (DSL version, arity, sorts)                                 |
| **Z3 Translation**          | `translator.py`                      | Encodes DSL into Z3 (DSL21Parser), builds solver, handles fact synthesis                |
| **Logic Feedback**          | `logic_feedback.py`                  | Interprets Z3 results (sat/unsat/unknown) into actionable feedback                      |
| **Explanation**             | `explanation_synthesizer.py`         | Phase 2.5: Generates human-readable summaries                                            |
| **Iteration Manager**       | `iteration_manager.py`               | Phase 3: Bounded refinement loop with state tracking                                     |
| **Judge Metric**            | `judge_runtime.py`                   | Phase 4: LLM-based evaluation of baseline vs. NSLA-v2 answers                           |
| **Canonical Rules**         | `canonical_rule_utils.py`            | Ensures query rules follow DSL conventions                                               |
| **Data Models**             | `models.py`, `models_v2.py`          | Pydantic schemas: LogicProgram, LLMOutput, IterationState, GuardrailResult, etc.        |

### **Testing & Validation**

The codebase includes comprehensive tests that validate each stage:

- **Unit Tests**: `test_translator_autodeclare.py`, `test_guardrail_checker.py`, `test_structured_extractor_ontology.py`, `test_logic_feedback.py`
- **Integration Tests**: `test_phase2_e2e.py`, `test_phase3_e2e.py`, `test_phase2_runtimes.py`
- **Golden Cases**: `test_nsla_v2_golden_cases.py` â€” validates legal reasoning patterns (contractual liability, tort law, usucapion)
- **Component Tests**: `test_iteration_manager.py`, `test_explanation_synthesizer.py`, `test_judge_runtime.py`
- **Smoke Tests**: `test_benchmark_smoke.py` â€” validates benchmark infrastructure

Run tests:
```bash
pytest -v
```

### **Research Value & Insights**

This architecture is designed for **failure-driven research**:

1. **Neuro-Symbolic Integration**: Demonstrates how LLMs can interface with formal reasoning (Z3) through a typed DSL, showcasing both strengths (structured extraction) and weaknesses (semantic loss).

2. **Formal Verification Layer**: The guardrail + translator pipeline ensures that only well-formed logical programs reach Z3, making failures attributable to reasoning (not syntax).

3. **Iterative Feedback Loop**: Phase 3 implements a bounded refinement mechanism where Z3 feedback (missing links, conflicts) guides LLM re-generationâ€”a pattern reusable in other symbolic AI domains.

4. **Documented Limitations**: The architecture exposes **why Z3 fails for legal reasoning**:
   - **Non-monotonicity**: Legal conclusions change with new context; Z3 assumes monotonic logic.
   - **Semantic loss**: NL â†’ DSL translation strips nuance (intent, context, interpretation).
   - **Over-specification**: Law tolerates ambiguity; Z3 requires complete, consistent axioms.
   - **Entailment mismatch**: SAT/UNSAT â‰  legal validity (e.g., contract interpretation involves policy, not pure logic).

5. **Reusable Components**: Despite the theoretical mismatch, the modules (structured extraction, ontology mapping, iterative refinement, guardrails) are **directly applicable** to domains where formal reasoning is viable (e.g., compliance checking, configuration synthesis, protocol verification).

6. **Benchmarking Infrastructure**: The test suite provides reproducible failure cases, enabling future research to measure progress on neuro-symbolic legal reasoning or pivot to better-suited formalisms (e.g., non-monotonic logics, probabilistic reasoning).

### **Why This Design Matters**

For **research recruiters** evaluating this project:
- This is not a failed productâ€”it's a **successful scientific experiment** that disproves a hypothesis.
- The architecture demonstrates **systems thinking**: modularity, testability, instrumentation (LLM status tracking, guardrails, feedback loops).
- The codebase is **publication-ready**: clear separation of concerns, comprehensive tests, documented limitations.
- The negative result **guides future research**: highlights where symbolic AI needs augmentation (e.g., probabilistic layers, defeasible reasoning, hybrid retrieval).

This project exemplifies the kind of **rigorous, failure-tolerant research** essential for advancing AI in complex, interpretive domains like law.

---

# ğŸ“¦ **4. Repository Structure**
```
nsla-v2/
â”œâ”€â”€ app/                           # Main application code (core logic)
â”‚   â”œâ”€â”€ templates/                 # Templates for prompts/UI
â”‚   â”œâ”€â”€ logic_dsl.py              # DSL specification (v2.1)
â”‚   â”œâ”€â”€ translator.py             # Z3 translator (DSL â†’ SMT)
â”‚   â”œâ”€â”€ pipeline_v2.py            # Main pipeline orchestration
â”‚   â”œâ”€â”€ guardrail_checker.py      # DSL validation & guardrails
â”‚   â”œâ”€â”€ structured_extractor.py   # Phase 2.2: NL â†’ DSL
â”‚   â”œâ”€â”€ canonicalizer_runtime.py  # Phase 2.1: Domain extraction
â”‚   â”œâ”€â”€ refinement_runtime.py     # Phase 2.3: Iterative refinement
â”‚   â”œâ”€â”€ explanation_synthesizer.py # Phase 2.5: Human-readable output
â”‚   â”œâ”€â”€ iteration_manager.py      # Phase 3: Bounded refinement loop
â”‚   â”œâ”€â”€ judge_runtime.py          # Phase 4: LLM-based evaluation
â”‚   â”œâ”€â”€ logic_feedback.py         # Z3 result interpretation
â”‚   â”œâ”€â”€ ontology_utils.py         # Ontology mapping utilities
â”‚   â”œâ”€â”€ models.py / models_v2.py  # Pydantic data models
â”‚   â””â”€â”€ ...                       # Other modules
â”œâ”€â”€ tests/                         # Comprehensive test suite
â”‚   â”œâ”€â”€ test_translator_autodeclare.py    # Unit: Z3 translator
â”‚   â”œâ”€â”€ test_guardrail_checker.py         # Unit: Guardrail validation
â”‚   â”œâ”€â”€ test_structured_extractor_ontology.py  # Unit: DSL extraction
â”‚   â”œâ”€â”€ test_logic_feedback.py            # Unit: Z3 feedback
â”‚   â”œâ”€â”€ test_phase2_e2e.py                # Integration: Phase 2
â”‚   â”œâ”€â”€ test_phase3_e2e.py                # Integration: Phase 3
â”‚   â”œâ”€â”€ test_nsla_v2_golden_cases.py      # Golden test cases
â”‚   â””â”€â”€ ...                               # Other tests
â”œâ”€â”€ docs/                          # Documentation
â”‚   â””â”€â”€ nsla_v2/                   # Project-specific docs
â”‚       â”œâ”€â”€ json/                  # JSON schemas/examples
â”‚       â”œâ”€â”€ reports/               # Analysis reports
â”‚       â”œâ”€â”€ dsl_nsla_v_2_1.md     # DSL guide
â”‚       â”œâ”€â”€ logic_dsl_v2.md       # DSL specification
â”‚       â”œâ”€â”€ nsla_v_2_phase_3_pipeline.md  # Phase 3 design
â”‚       â””â”€â”€ ...                    # Other documentation
â”œâ”€â”€ data/                          # Test cases & benchmark results
â”‚   â”œâ”€â”€ cases_dev.json            # Development test cases
â”‚   â””â”€â”€ results_*.csv             # Benchmark outputs
â”œâ”€â”€ resources/                     # Static resources
â”‚   â”œâ”€â”€ ontology/                 # Legal domain ontology
â”‚   â”‚   â””â”€â”€ legal_it_v1.yaml     # Italian legal ontology
â”‚   â”œâ”€â”€ prompts/                  # LLM prompt templates
â”‚   â”‚   â”œâ”€â”€ phase3/              # Phase 3 prompts
â”‚   â”‚   â””â”€â”€ judge/               # Judge LLM prompts
â”‚   â””â”€â”€ specs/                    # Formal specifications
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ inspect_subset_guardrail.py
â”‚   â””â”€â”€ manual_sanity.py
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ nsla_v2_paper_en.md           # Research paper (English)
â””â”€â”€ nsla_v2_paper_it.md           # Research paper (Italian)
```

---

# ğŸ”¬ **5. Key Findings**
### âœ” What works well
- DSL design is clean and expressive.
- Guardrail system handles malformed DSL robustly.
- Z3 encodings are deterministic and well-formed.
- Unit and integration tests pass consistently on structured cases.
- Pipeline is modular and maintainable.

### âœ˜ What fundamentally fails
1. **Semantic loss**: Natural language â†’ DSL strips essential meaning.
2. **Non-monotonicity**: Legal reasoning changes with added context; SMT cannot.
3. **Over-specification**: Law tolerates ambiguity; Z3 requires completeness.
4. **Interpretive reasoning**: Legal judgement is contextual, not purely logical.
5. **Entailment mismatch**: Solver SAT/UNSAT â‰  legal validity.

### ğŸ“ Scientific insight
> Legal reasoning cannot be reliably reduced to monotonic logical entailment.

This negative result is useful to guide future research.

---

# ğŸ§ª **6. Experiments & Testing**
NSLA-v2 includes:
- DSL validation tests
- Z3 translator tests
- end-to-end pipeline tests
- adversarial malformed-DSL scenarios
- benchmark micro-cases (contracts, obligations, contradictions)

Run tests:
```bash
pytest -v
```

---

# âš ï¸ **7. Project Status**
### **Status: Paused Research Prototype**
The project is kept public as:
- a case study of neuro-symbolic system design,
- a record of limitations of SMT-based legal reasoning,
- a foundation for future experiments.

See: `docs/PAPER_DRAFT_EN.md` for full explanation.

---

# ğŸ”­ **8. Future Research Directions**
This project directly inspired several more promising lines of work:


### ** 1. Neuro-Symbolic Concept Generator**
Generate abstract mathematical propositions â†’ verify with Z3.

### **3. Fractal Reasoning Engine**
Multi-layer reasoning engine with internal self-verification loops.

All of these exploit the strengths of symbolic solvers without forcing them into domains they cannot model.

---

# â–¶ï¸ **9. How to Use / Run**
Install dependencies:
```bash
pip install -r requirements.txt
```

Execute pipeline (example):
```bash
python src/pipeline_iterative.py
```

Run benchmarks:
```bash
pytest -v tests/
```

---

# ğŸ‘¤ **10. Author**
This project was developed by **Matteo Panzeri**, with the assistance of advanced LLM-based research tools used responsibly to accelerate architectural exploration, debugging, and documentation.

---

# ğŸ“„ **11. License**
MIT License (recommended for research prototypes).
